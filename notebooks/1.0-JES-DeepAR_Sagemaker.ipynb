{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ec312c-35da-41ce-b153-f09c819b976e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.67)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: pyathena in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: pyarrow in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (15.0.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.67 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.34.67)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyathena) (2024.2.0)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyathena) (8.2.3)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.67->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 pandas pyathena pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd372d3-a579-44d6-af2c-8aea2146d536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import s3fs\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ba337f-8243-43d8-8a5e-80b5603cfac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# at this point, I will have predictions from last week for current data\n",
    "# and current actuals\n",
    "# need to merge the latest weekly data with the predictions from last week\n",
    "# how to get the latest weekly_actuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974bf6ea-80c1-46f8-b19b-2014459c41f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a722d9-d467-41ce-911e-27fe792c461a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Boto3 Athena client\n",
    "athena_client = boto3.client('athena', region_name='us-east-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772100ab-aefe-4372-9908-9021f643e61e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed successfully. Results are stored in the directory: s3://nndss/query_results/weekly_combined_data/f745c878-7b09-44c1-8aff-8f848b122886/\n"
     ]
    }
   ],
   "source": [
    "# combine historical and latest data\n",
    "#sql_query = \"\"\"\n",
    "#SELECT * FROM (\n",
    "#    SELECT item_id, year, week, date, label, new_cases\n",
    "#    FROM weekly\n",
    "#    UNION ALL\n",
    "#    SELECT item_id, year, week, date, label, new_cases\n",
    "#    FROM weekly_staging\n",
    "#) AS combined_data\n",
    "#\"\"\"\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT item_id, year, week, date, label, new_cases \n",
    "FROM weekly\n",
    "\"\"\"\n",
    "\n",
    "# Specify the Athena database and S3 output location\n",
    "database = 'cdc_nndss'\n",
    "s3_output_constant = 's3://nndss/query_results/weekly_combined_data'\n",
    "\n",
    "# Adjust the ResultConfiguration to use the constant output location\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=sql_query,\n",
    "    QueryExecutionContext={'Database': database},\n",
    "    ResultConfiguration={'OutputLocation': s3_output_constant}\n",
    ")\n",
    "\n",
    "# Get the query execution ID\n",
    "query_execution_id = response['QueryExecutionId']\n",
    "\n",
    "# Function to check the query execution status\n",
    "def wait_for_query_completion(client, query_id):\n",
    "    while True:\n",
    "        response = client.get_query_execution(QueryExecutionId=query_id)\n",
    "        state = response['QueryExecution']['Status']['State']\n",
    "        if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "            return state\n",
    "        time.sleep(5)\n",
    "\n",
    "# Wait for the query to complete\n",
    "query_state = wait_for_query_completion(athena_client, query_execution_id)\n",
    "if query_state == 'SUCCEEDED':\n",
    "    print(f\"Query completed successfully. Results are stored in the directory: {s3_output_constant}/{query_execution_id}/\")\n",
    "elif query_state in ['FAILED', 'CANCELLED']:\n",
    "    print(f\"Query did not complete successfully. State: {query_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32911c46-c267-4e4f-be50-b96bbcbb8372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA_Anthrax</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-03 00:00:00.000</td>\n",
       "      <td>Anthrax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALABAMA_Anthrax</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-10 00:00:00.000</td>\n",
       "      <td>Anthrax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALABAMA_Anthrax</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-17 00:00:00.000</td>\n",
       "      <td>Anthrax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALABAMA_Anthrax</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-24 00:00:00.000</td>\n",
       "      <td>Anthrax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALABAMA_Anthrax</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-31 00:00:00.000</td>\n",
       "      <td>Anthrax</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           item_id  year  week                     date    label  new_cases\n",
       "0  ALABAMA_Anthrax  2022     1  2022-01-03 00:00:00.000  Anthrax        NaN\n",
       "1  ALABAMA_Anthrax  2022     2  2022-01-10 00:00:00.000  Anthrax        NaN\n",
       "2  ALABAMA_Anthrax  2022     3  2022-01-17 00:00:00.000  Anthrax        NaN\n",
       "3  ALABAMA_Anthrax  2022     4  2022-01-24 00:00:00.000  Anthrax        NaN\n",
       "4  ALABAMA_Anthrax  2022     5  2022-01-31 00:00:00.000  Anthrax        NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_file_path = f\"{s3_output_constant}/{query_execution_id}.csv\"\n",
    "df = pd.read_csv(result_file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5538b5a-eaf2-4e34-a448-7173f0cc33a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'date' to the appropriate datetime format if not already\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sort the DataFrame by 'item_id' and 'date' to ensure the order of the time series\n",
    "df.sort_values(by=['item_id', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee9987b8-090b-456f-86c1-d5b379b77ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = df[df.date<pd.to_datetime(\"2024-03-11\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d0910a2-0f90-4012-828a-aa837364a199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697452</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697453</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697454</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697455</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697456</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697561</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-05</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697562</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697563</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697564</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697565</th>\n",
       "      <td>WYOMING_Zika virus disease, non-congenital</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>Zika virus disease, non-congenital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           item_id  year  week       date  \\\n",
       "697452  WYOMING_Zika virus disease, non-congenital  2022     1 2022-01-03   \n",
       "697453  WYOMING_Zika virus disease, non-congenital  2022     2 2022-01-10   \n",
       "697454  WYOMING_Zika virus disease, non-congenital  2022     3 2022-01-17   \n",
       "697455  WYOMING_Zika virus disease, non-congenital  2022     4 2022-01-24   \n",
       "697456  WYOMING_Zika virus disease, non-congenital  2022     5 2022-01-31   \n",
       "...                                            ...   ...   ...        ...   \n",
       "697561  WYOMING_Zika virus disease, non-congenital  2024     6 2024-02-05   \n",
       "697562  WYOMING_Zika virus disease, non-congenital  2024     7 2024-02-12   \n",
       "697563  WYOMING_Zika virus disease, non-congenital  2024     8 2024-02-19   \n",
       "697564  WYOMING_Zika virus disease, non-congenital  2024     9 2024-02-26   \n",
       "697565  WYOMING_Zika virus disease, non-congenital  2024    10 2024-03-04   \n",
       "\n",
       "                                     label  new_cases  \n",
       "697452  Zika virus disease, non-congenital        NaN  \n",
       "697453  Zika virus disease, non-congenital        NaN  \n",
       "697454  Zika virus disease, non-congenital        NaN  \n",
       "697455  Zika virus disease, non-congenital        NaN  \n",
       "697456  Zika virus disease, non-congenital        NaN  \n",
       "...                                    ...        ...  \n",
       "697561  Zika virus disease, non-congenital        NaN  \n",
       "697562  Zika virus disease, non-congenital        NaN  \n",
       "697563  Zika virus disease, non-congenital        NaN  \n",
       "697564  Zika virus disease, non-congenital        NaN  \n",
       "697565  Zika virus disease, non-congenital        NaN  \n",
       "\n",
       "[114 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.item_id=='WYOMING_Zika virus disease, non-congenital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e99729c-e72c-427f-8d5c-412b696169b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "output_bucket = 'nndss'\n",
    "output_key = 'deepar_input_data/deepar_dataset.jsonl'\n",
    "s3_output_path = f's3://{output_bucket}/{output_key}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d8624ee-730f-488c-a80f-5b0ac48b43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function to convert NaN values to \"NaN\" string and others to float\n",
    "def convert_target(target_series):\n",
    "    return [float(x) if pd.notna(x) else \"NaN\" for x in target_series]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3243d968-ac81-4908-a338-f5c5d5b110cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_mapping = {}  # To store the mapping of item_id to its index in the JSON Lines file\n",
    "json_lines = []  # To store the JSON Lines\n",
    "\n",
    "for idx, (item_id, group) in enumerate(df.groupby('item_id')):\n",
    "    time_series = {\n",
    "        \"start\": str(group['date'].dt.date.iloc[0]),  # Assuming the 'date' column is already a datetime\n",
    "        \"target\": convert_target(group['new_cases']),\n",
    "    }\n",
    "    json_lines.append(json.dumps(time_series))\n",
    "    time_series_mapping[item_id] = idx  # Map item_id to its index in the JSON Lines file\n",
    "\n",
    "# Convert JSON Lines list to a single string\n",
    "json_lines_str = \"\\n\".join(json_lines)\n",
    "\n",
    "# Define S3 keys for the JSON Lines file and the mapping file\n",
    "json_lines_key = 'deepar_input_data/deepar_dataset.jsonl'\n",
    "mapping_key = 'deepar_input_data/time_series_mapping.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46c7151a-ce4e-4b66-bfa7-12ebd265eb23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Lines file saved to s3://nndss/deepar_input_data/deepar_dataset.jsonl\n",
      "Mapping file saved to s3://nndss/deepar_input_data/time_series_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# Save the JSON Lines file to S3\n",
    "s3.Object(output_bucket, json_lines_key).put(Body=json_lines_str)\n",
    "\n",
    "# Save the mapping file to S3\n",
    "mapping_str = json.dumps(time_series_mapping)\n",
    "s3.Object(output_bucket, mapping_key).put(Body=mapping_str)\n",
    "\n",
    "print(f\"JSON Lines file saved to s3://{output_bucket}/{json_lines_key}\")\n",
    "print(f\"Mapping file saved to s3://{output_bucket}/{mapping_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a371beb-10ec-468c-b935-d58f03376721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': '2022-01-03', 'target': ['NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN']}\n"
     ]
    }
   ],
   "source": [
    "print(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a1a375a-3119-4daf-8369-fd5756904cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris, Session\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.session import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fa71f76-2898-419b-b459-b8e7c2d50ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()  # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "264ac39a-9954-4069-83eb-44b98d6fd61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = image_uris.retrieve('forecasting-deepar', region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e652be5d-c916-4ba7-a107-8585d6e6ed2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure the estimator\n",
    "deepar = Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    output_path=f's3://{output_bucket}/deepar/output',\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d665c25-119b-4b9f-a9e6-fd1183f502e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deepar.set_hyperparameters(\n",
    "    time_freq='W',\n",
    "    epochs=20,\n",
    "    early_stopping_patience=10,\n",
    "    prediction_length=1,\n",
    "    context_length=1,\n",
    "    num_cells=40,\n",
    "    num_layers=2,\n",
    "    mini_batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    dropout_rate=0.05,\n",
    "    likelihood='negative-binomial'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b234bc2a-a27b-4a08-80df-9f3d682db781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify data channels\n",
    "data_channels = {\n",
    "    'train': f's3://{output_bucket}/deepar_input_data/deepar_dataset.jsonl',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cfc3496-b06c-4523-8e45-c411d14492ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: forecasting-deepar-2024-03-23-17-21-42-127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 17:21:42 Starting - Starting the training job...\n",
      "2024-03-23 17:21:57 Starting - Preparing the instances for training......\n",
      "2024-03-23 17:22:51 Downloading - Downloading input data...\n",
      "2024-03-23 17:23:21 Downloading - Downloading the training image...............\n",
      "2024-03-23 17:26:12 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '1', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'epochs': '20', 'learning_rate': '0.001', 'likelihood': 'negative-binomial', 'mini_batch_size': '64', 'num_cells': '40', 'num_layers': '2', 'prediction_length': '1', 'time_freq': 'W'}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'negative-binomial', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '1', 'epochs': '20', 'prediction_length': '1', 'time_freq': 'W'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] random_seed is None\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/deepar_dataset.jsonl` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:24 INFO 140470849898304] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/deepar_dataset.jsonl` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Training set statistics:\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Integer time series\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] number of time series: 6840\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] number of observations: 691467\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] mean target length: 101.09166666666667\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] min/mean/max target: 0.0/3.137685529461276/5601.0\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] mean abs(target): 3.137685529461276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] contains missing values: yes (93.4%)\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #memory_usage::<batchbuffer> = 0.67138671875 mb\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] nvidia-smi: took 0.056 seconds to run.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214785.4751887, \"EndTime\": 1711214785.486095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 9.892940521240234, \"count\": 1, \"min\": 9.892940521240234, \"max\": 9.892940521240234}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #memory_usage::<model> = 0 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214785.486167, \"EndTime\": 1711214785.4991167, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 23.794889450073242, \"count\": 1, \"min\": 23.794889450073242, \"max\": 23.794889450073242}}}\u001b[0m\n",
      "\u001b[34m[17:26:25] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.404.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 10240 bytes with malloc directly\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch[0] avg_epoch_loss=0.293717\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=0.29371678829193115\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch[5] avg_epoch_loss=0.209395\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=0.20939514630784592\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch [5]#011Speed: 10082.99 samples/sec#011loss=0.209395\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch[10] avg_epoch_loss=0.317447\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=0.447109991312027\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch [10]#011Speed: 1749.96 samples/sec#011loss=0.447110\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch[15] avg_epoch_loss=0.341148\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=0.3932895451784134\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:25 INFO 140470849898304] Epoch[0] Batch [15]#011Speed: 11594.08 samples/sec#011loss=0.393290\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[20] avg_epoch_loss=0.302007\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=0.17675561159849168\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [20]#011Speed: 1825.65 samples/sec#011loss=0.176756\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[25] avg_epoch_loss=0.264715\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=0.10809035450220109\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [25]#011Speed: 11866.65 samples/sec#011loss=0.108090\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[30] avg_epoch_loss=0.237470\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=0.0957967571914196\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [30]#011Speed: 1893.26 samples/sec#011loss=0.095797\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[35] avg_epoch_loss=0.219437\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=0.10762662887573242\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [35]#011Speed: 10408.27 samples/sec#011loss=0.107627\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[40] avg_epoch_loss=0.212100\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=0.15927944257855414\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [40]#011Speed: 1827.37 samples/sec#011loss=0.159279\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[45] avg_epoch_loss=0.211629\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=0.20776686072349548\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [45]#011Speed: 11122.89 samples/sec#011loss=0.207767\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[50] avg_epoch_loss=0.214572\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=0.241640105843544\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [50]#011Speed: 1878.93 samples/sec#011loss=0.241640\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[55] avg_epoch_loss=0.206345\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=0.12243546694517135\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [55]#011Speed: 11153.86 samples/sec#011loss=0.122435\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[60] avg_epoch_loss=0.215072\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=0.31281199157238004\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [60]#011Speed: 1752.35 samples/sec#011loss=0.312812\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch[65] avg_epoch_loss=0.213340\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=0.19221754968166352\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:26 INFO 140470849898304] Epoch[0] Batch [65]#011Speed: 11324.29 samples/sec#011loss=0.192218\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[70] avg_epoch_loss=0.214448\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=0.22906455993652344\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [70]#011Speed: 1886.23 samples/sec#011loss=0.229065\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[75] avg_epoch_loss=0.213349\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=0.1977506548166275\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [75]#011Speed: 11655.80 samples/sec#011loss=0.197751\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[80] avg_epoch_loss=0.212959\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=0.20702082961797713\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [80]#011Speed: 1874.41 samples/sec#011loss=0.207021\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[85] avg_epoch_loss=0.211367\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=0.18557503670454026\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [85]#011Speed: 11526.28 samples/sec#011loss=0.185575\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[90] avg_epoch_loss=0.204900\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=0.09367805682122707\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [90]#011Speed: 1340.38 samples/sec#011loss=0.093678\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[95] avg_epoch_loss=0.201249\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=0.13479675501585006\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [95]#011Speed: 8028.91 samples/sec#011loss=0.134797\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[100] avg_epoch_loss=0.204002\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=0.2568589873611927\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [100]#011Speed: 1535.68 samples/sec#011loss=0.256859\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch[105] avg_epoch_loss=0.206978\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=0.26710466742515565\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Epoch[0] Batch [105]#011Speed: 8225.18 samples/sec#011loss=0.267105\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] processed a total of 6864 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214785.4991682, \"EndTime\": 1711214787.8791, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 2379.8203468322754, \"count\": 1, \"min\": 2379.8203468322754, \"max\": 2379.8203468322754}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=2884.046764715252 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] #quality_metric: host=algo-1, epoch=0, train loss <loss>=0.2053900812925012\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:27 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_904a46b9-e548-45a7-a0e2-bcdc762123a8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214787.8792071, \"EndTime\": 1711214787.886933, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 7.0133209228515625, \"count\": 1, \"min\": 7.0133209228515625, \"max\": 7.0133209228515625}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[0] avg_epoch_loss=0.354152\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=0.3541516363620758\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[5] avg_epoch_loss=0.391794\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=0.3917935478190581\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [5]#011Speed: 9349.70 samples/sec#011loss=0.391794\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[10] avg_epoch_loss=0.334228\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=0.2651500776410103\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [10]#011Speed: 1789.15 samples/sec#011loss=0.265150\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[15] avg_epoch_loss=0.289171\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=0.19004567265510558\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [15]#011Speed: 9438.00 samples/sec#011loss=0.190046\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[20] avg_epoch_loss=0.259723\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=0.1654895931482315\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [20]#011Speed: 1317.87 samples/sec#011loss=0.165490\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[25] avg_epoch_loss=0.236373\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=0.13830167502164842\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [25]#011Speed: 7739.19 samples/sec#011loss=0.138302\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[30] avg_epoch_loss=0.217801\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=0.12122905775904655\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [30]#011Speed: 1213.45 samples/sec#011loss=0.121229\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch[35] avg_epoch_loss=0.205471\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=0.1290192686021328\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:28 INFO 140470849898304] Epoch[1] Batch [35]#011Speed: 8051.65 samples/sec#011loss=0.129019\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[40] avg_epoch_loss=0.202553\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=0.18154884204268457\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [40]#011Speed: 1595.78 samples/sec#011loss=0.181549\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[45] avg_epoch_loss=0.205997\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=0.2342321127653122\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [45]#011Speed: 11717.98 samples/sec#011loss=0.234232\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[50] avg_epoch_loss=0.200081\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=0.14565776214003562\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [50]#011Speed: 1590.85 samples/sec#011loss=0.145658\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[55] avg_epoch_loss=0.203581\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=0.2392861943691969\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [55]#011Speed: 10031.00 samples/sec#011loss=0.239286\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[60] avg_epoch_loss=0.200302\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=0.16356920599937438\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [60]#011Speed: 1809.96 samples/sec#011loss=0.163569\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[65] avg_epoch_loss=0.219324\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=0.45139275416731833\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [65]#011Speed: 10104.55 samples/sec#011loss=0.451393\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[70] avg_epoch_loss=0.213486\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=0.13642349988222122\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [70]#011Speed: 1886.91 samples/sec#011loss=0.136423\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[75] avg_epoch_loss=0.211231\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=0.17921383082866668\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [75]#011Speed: 10262.55 samples/sec#011loss=0.179214\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch[80] avg_epoch_loss=0.209962\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=0.19068065285682678\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:29 INFO 140470849898304] Epoch[1] Batch [80]#011Speed: 1819.88 samples/sec#011loss=0.190681\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch[85] avg_epoch_loss=0.204175\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=0.1104232395067811\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch [85]#011Speed: 10135.61 samples/sec#011loss=0.110423\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch[90] avg_epoch_loss=0.201266\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=0.15122685581445694\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch [90]#011Speed: 1792.57 samples/sec#011loss=0.151227\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch[95] avg_epoch_loss=0.199028\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=0.15830103009939195\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch [95]#011Speed: 10130.63 samples/sec#011loss=0.158301\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch[100] avg_epoch_loss=0.196756\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=0.15312170535326003\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch [100]#011Speed: 2090.92 samples/sec#011loss=0.153122\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch[105] avg_epoch_loss=0.194305\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=0.1448006808757782\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[1] Batch [105]#011Speed: 10047.21 samples/sec#011loss=0.144801\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] processed a total of 6908 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214787.8869967, \"EndTime\": 1711214790.421897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2534.848213195801, \"count\": 1, \"min\": 2534.848213195801, \"max\": 2534.848213195801}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=2725.101245838411 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=1, train loss <loss>=0.19378034755829032\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_29941dcf-f4e9-4f92-aa29-275d431ac7b6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214790.421969, \"EndTime\": 1711214790.4270942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 4.651308059692383, \"count\": 1, \"min\": 4.651308059692383, \"max\": 4.651308059692383}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch[0] avg_epoch_loss=0.152219\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=0.15221895277500153\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch[5] avg_epoch_loss=0.223522\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=0.22352243214845657\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch [5]#011Speed: 11603.40 samples/sec#011loss=0.223522\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch[10] avg_epoch_loss=0.267569\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=0.3204247549176216\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch [10]#011Speed: 1870.18 samples/sec#011loss=0.320425\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch[15] avg_epoch_loss=0.253182\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=0.221530045568943\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch [15]#011Speed: 9393.01 samples/sec#011loss=0.221530\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch[20] avg_epoch_loss=0.251639\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=0.24670348539948464\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:30 INFO 140470849898304] Epoch[2] Batch [20]#011Speed: 1793.89 samples/sec#011loss=0.246703\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[25] avg_epoch_loss=0.222820\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=0.10177958756685257\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [25]#011Speed: 10377.04 samples/sec#011loss=0.101780\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[30] avg_epoch_loss=0.215129\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=0.1751355491578579\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [30]#011Speed: 1805.27 samples/sec#011loss=0.175136\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[35] avg_epoch_loss=0.204623\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=0.13948750942945481\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [35]#011Speed: 10090.57 samples/sec#011loss=0.139488\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[40] avg_epoch_loss=0.197014\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=0.1422285795211792\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [40]#011Speed: 1854.38 samples/sec#011loss=0.142229\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[45] avg_epoch_loss=0.190286\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=0.1351185232400894\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [45]#011Speed: 10105.39 samples/sec#011loss=0.135119\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[50] avg_epoch_loss=0.189297\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=0.1801984466612339\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [50]#011Speed: 1901.53 samples/sec#011loss=0.180198\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[55] avg_epoch_loss=0.179895\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=0.08398561291396618\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [55]#011Speed: 11786.20 samples/sec#011loss=0.083986\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[60] avg_epoch_loss=0.176772\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=0.14180276580154896\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [60]#011Speed: 1841.06 samples/sec#011loss=0.141803\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch[65] avg_epoch_loss=0.174455\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=0.14618517607450485\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:31 INFO 140470849898304] Epoch[2] Batch [65]#011Speed: 11096.87 samples/sec#011loss=0.146185\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[70] avg_epoch_loss=0.175230\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=0.18545675948262214\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [70]#011Speed: 1822.91 samples/sec#011loss=0.185457\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[75] avg_epoch_loss=0.179642\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=0.2422955960035324\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [75]#011Speed: 10026.50 samples/sec#011loss=0.242296\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[80] avg_epoch_loss=0.212620\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=0.713890540599823\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [80]#011Speed: 1614.00 samples/sec#011loss=0.713891\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[85] avg_epoch_loss=0.210041\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=0.1682467930018902\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [85]#011Speed: 11372.94 samples/sec#011loss=0.168247\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[90] avg_epoch_loss=0.217119\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=0.3388776630163193\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [90]#011Speed: 1947.68 samples/sec#011loss=0.338878\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[95] avg_epoch_loss=0.213769\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=0.1527904361486435\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [95]#011Speed: 9717.40 samples/sec#011loss=0.152790\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[100] avg_epoch_loss=0.232068\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=0.5834054797887802\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [100]#011Speed: 2421.68 samples/sec#011loss=0.583405\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch[105] avg_epoch_loss=0.226633\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=0.11684928983449935\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[2] Batch [105]#011Speed: 10316.74 samples/sec#011loss=0.116849\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] processed a total of 6847 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214790.4271524, \"EndTime\": 1711214792.6326907, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2205.4858207702637, \"count\": 1, \"min\": 2205.4858207702637, \"max\": 2205.4858207702637}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3104.4001907280276 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=2, train loss <loss>=0.22648268537682908\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[3] Batch[0] avg_epoch_loss=0.140250\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=0.14024989306926727\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[3] Batch[5] avg_epoch_loss=0.197771\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=0.19777057195703188\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[3] Batch [5]#011Speed: 10479.87 samples/sec#011loss=0.197771\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[3] Batch[10] avg_epoch_loss=0.249864\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=0.31237624436616895\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:32 INFO 140470849898304] Epoch[3] Batch [10]#011Speed: 1830.97 samples/sec#011loss=0.312376\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[15] avg_epoch_loss=0.251042\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=0.2536328971385956\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [15]#011Speed: 10268.36 samples/sec#011loss=0.253633\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[20] avg_epoch_loss=0.271283\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=0.336056099832058\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [20]#011Speed: 1871.03 samples/sec#011loss=0.336056\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[25] avg_epoch_loss=0.250693\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=0.16421165093779563\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [25]#011Speed: 10160.62 samples/sec#011loss=0.164212\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[30] avg_epoch_loss=0.238729\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=0.17651982456445695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [30]#011Speed: 1723.81 samples/sec#011loss=0.176520\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[35] avg_epoch_loss=0.237276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=0.22826228775084018\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [35]#011Speed: 10130.79 samples/sec#011loss=0.228262\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[40] avg_epoch_loss=0.223905\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=0.12763894647359847\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [40]#011Speed: 1813.17 samples/sec#011loss=0.127639\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[45] avg_epoch_loss=0.227837\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=0.26007319688797\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [45]#011Speed: 10096.04 samples/sec#011loss=0.260073\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[50] avg_epoch_loss=0.222231\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=0.17066406458616257\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [50]#011Speed: 1901.45 samples/sec#011loss=0.170664\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch[55] avg_epoch_loss=0.214568\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=0.13640107810497284\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:33 INFO 140470849898304] Epoch[3] Batch [55]#011Speed: 10254.08 samples/sec#011loss=0.136401\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[60] avg_epoch_loss=0.209794\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=0.1563262477517128\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [60]#011Speed: 1821.86 samples/sec#011loss=0.156326\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[65] avg_epoch_loss=0.233619\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=0.5242831230163574\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [65]#011Speed: 10113.53 samples/sec#011loss=0.524283\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[70] avg_epoch_loss=0.231194\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=0.19918480515480042\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [70]#011Speed: 1704.63 samples/sec#011loss=0.199185\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[75] avg_epoch_loss=0.237832\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=0.33208792209625243\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [75]#011Speed: 11714.81 samples/sec#011loss=0.332088\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[80] avg_epoch_loss=0.237796\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=0.23724680691957473\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [80]#011Speed: 1594.01 samples/sec#011loss=0.237247\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[85] avg_epoch_loss=0.233896\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=0.1707194119691849\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [85]#011Speed: 9990.53 samples/sec#011loss=0.170719\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[90] avg_epoch_loss=0.226678\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=0.10252545941621065\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [90]#011Speed: 1825.16 samples/sec#011loss=0.102525\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[95] avg_epoch_loss=0.223508\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=0.16582061797380448\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [95]#011Speed: 9745.20 samples/sec#011loss=0.165821\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[100] avg_epoch_loss=0.217464\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=0.10141643807291985\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [100]#011Speed: 2230.89 samples/sec#011loss=0.101416\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch[105] avg_epoch_loss=0.213300\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=0.1291816310957074\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] Epoch[3] Batch [105]#011Speed: 10044.96 samples/sec#011loss=0.129182\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] processed a total of 6906 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214792.6327527, \"EndTime\": 1711214794.896188, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2263.0202770233154, \"count\": 1, \"min\": 2263.0202770233154, \"max\": 2263.0202770233154}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3051.529266680327 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] #quality_metric: host=algo-1, epoch=3, train loss <loss>=0.21083764756029402\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:34 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[0] avg_epoch_loss=0.332934\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=0.332933634519577\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[5] avg_epoch_loss=0.184695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=0.18469538229207197\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [5]#011Speed: 10013.56 samples/sec#011loss=0.184695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[10] avg_epoch_loss=0.227913\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=0.27977433502674104\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [10]#011Speed: 1789.45 samples/sec#011loss=0.279774\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[15] avg_epoch_loss=0.239145\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=0.26385424137115476\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [15]#011Speed: 9944.85 samples/sec#011loss=0.263854\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[20] avg_epoch_loss=0.214893\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=0.13728804811835288\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [20]#011Speed: 1766.16 samples/sec#011loss=0.137288\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[25] avg_epoch_loss=0.196281\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=0.11811098009347916\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [25]#011Speed: 10275.12 samples/sec#011loss=0.118111\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[30] avg_epoch_loss=0.180607\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=0.09909838363528252\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [30]#011Speed: 1770.63 samples/sec#011loss=0.099098\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[35] avg_epoch_loss=0.177449\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=0.15787105038762092\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [35]#011Speed: 10440.41 samples/sec#011loss=0.157871\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[40] avg_epoch_loss=0.172871\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=0.1399089053273201\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [40]#011Speed: 1832.67 samples/sec#011loss=0.139909\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch[45] avg_epoch_loss=0.170368\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=0.14984827041625975\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:35 INFO 140470849898304] Epoch[4] Batch [45]#011Speed: 9879.99 samples/sec#011loss=0.149848\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[50] avg_epoch_loss=0.172348\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=0.19055978432297707\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [50]#011Speed: 1773.86 samples/sec#011loss=0.190560\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[55] avg_epoch_loss=0.165703\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=0.09792222678661347\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [55]#011Speed: 10648.99 samples/sec#011loss=0.097922\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[60] avg_epoch_loss=0.164912\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=0.1560599260032177\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [60]#011Speed: 1864.30 samples/sec#011loss=0.156060\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[65] avg_epoch_loss=0.172429\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=0.2641261398792267\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [65]#011Speed: 11592.88 samples/sec#011loss=0.264126\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[70] avg_epoch_loss=0.185322\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=0.3555090695619583\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [70]#011Speed: 1867.29 samples/sec#011loss=0.355509\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[75] avg_epoch_loss=0.189634\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=0.25087179988622665\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [75]#011Speed: 11251.85 samples/sec#011loss=0.250872\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[80] avg_epoch_loss=0.190627\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=0.20572302341461182\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [80]#011Speed: 1768.85 samples/sec#011loss=0.205723\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[85] avg_epoch_loss=0.190338\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=0.18565937429666518\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [85]#011Speed: 10326.27 samples/sec#011loss=0.185659\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[90] avg_epoch_loss=0.187247\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=0.13407387547194957\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [90]#011Speed: 1823.77 samples/sec#011loss=0.134074\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch[95] avg_epoch_loss=0.184927\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=0.14269762188196183\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:36 INFO 140470849898304] Epoch[4] Batch [95]#011Speed: 10175.41 samples/sec#011loss=0.142698\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[4] Batch[100] avg_epoch_loss=0.183123\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=0.14849671050906182\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[4] Batch [100]#011Speed: 2125.03 samples/sec#011loss=0.148497\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[4] Batch[105] avg_epoch_loss=0.185626\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=0.236177060008049\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[4] Batch [105]#011Speed: 10876.55 samples/sec#011loss=0.236177\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] processed a total of 6917 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214794.8962612, \"EndTime\": 1711214797.1453662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2248.656988143921, \"count\": 1, \"min\": 2248.656988143921, \"max\": 2248.656988143921}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3075.912849420966 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=4, train loss <loss>=0.18228108854537164\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_c213c8bf-d488-435a-be80-ea469da873a1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214797.145438, \"EndTime\": 1711214797.150409, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 4.610776901245117, \"count\": 1, \"min\": 4.610776901245117, \"max\": 4.610776901245117}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[0] avg_epoch_loss=0.228159\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=0.2281593531370163\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[5] avg_epoch_loss=0.246788\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=0.24678785974780718\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [5]#011Speed: 9877.67 samples/sec#011loss=0.246788\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[10] avg_epoch_loss=0.245548\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=0.24405950531363488\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [10]#011Speed: 1764.03 samples/sec#011loss=0.244060\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[15] avg_epoch_loss=0.234207\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=0.2092588275671005\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [15]#011Speed: 10750.40 samples/sec#011loss=0.209259\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[20] avg_epoch_loss=0.227620\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=0.20653820410370827\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [20]#011Speed: 1826.98 samples/sec#011loss=0.206538\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[25] avg_epoch_loss=0.213347\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=0.15340207740664483\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [25]#011Speed: 11711.64 samples/sec#011loss=0.153402\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[30] avg_epoch_loss=0.194878\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=0.09883876815438271\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [30]#011Speed: 1821.12 samples/sec#011loss=0.098839\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch[35] avg_epoch_loss=0.183482\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=0.11282929480075836\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:37 INFO 140470849898304] Epoch[5] Batch [35]#011Speed: 11799.57 samples/sec#011loss=0.112829\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[40] avg_epoch_loss=0.185862\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=0.2029967039823532\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [40]#011Speed: 1812.67 samples/sec#011loss=0.202997\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[45] avg_epoch_loss=0.188250\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=0.20782720148563386\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [45]#011Speed: 10460.83 samples/sec#011loss=0.207827\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[50] avg_epoch_loss=0.189669\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=0.20273249000310897\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [50]#011Speed: 1829.02 samples/sec#011loss=0.202732\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[55] avg_epoch_loss=0.183387\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=0.11930496767163276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [55]#011Speed: 11711.84 samples/sec#011loss=0.119305\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[60] avg_epoch_loss=0.176959\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=0.10497102420777082\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [60]#011Speed: 1857.98 samples/sec#011loss=0.104971\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[65] avg_epoch_loss=0.176782\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=0.17462438642978667\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [65]#011Speed: 11740.12 samples/sec#011loss=0.174624\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[70] avg_epoch_loss=0.178531\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=0.20160552710294724\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [70]#011Speed: 1819.22 samples/sec#011loss=0.201606\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[75] avg_epoch_loss=0.184816\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=0.2740720063447952\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [75]#011Speed: 10039.32 samples/sec#011loss=0.274072\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[80] avg_epoch_loss=0.204824\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=0.508945855498314\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [80]#011Speed: 1809.89 samples/sec#011loss=0.508946\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch[85] avg_epoch_loss=0.199137\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=0.1070025771856308\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:38 INFO 140470849898304] Epoch[5] Batch [85]#011Speed: 10229.54 samples/sec#011loss=0.107003\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch[90] avg_epoch_loss=0.195601\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=0.13478478342294692\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch [90]#011Speed: 1734.87 samples/sec#011loss=0.134785\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch[95] avg_epoch_loss=0.194174\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=0.16819972470402716\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch [95]#011Speed: 10224.55 samples/sec#011loss=0.168200\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch[100] avg_epoch_loss=0.189611\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=0.10199276059865951\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch [100]#011Speed: 2591.10 samples/sec#011loss=0.101993\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch[105] avg_epoch_loss=0.186232\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=0.11797612234950065\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[5] Batch [105]#011Speed: 10519.95 samples/sec#011loss=0.117976\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] processed a total of 6797 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214797.150474, \"EndTime\": 1711214799.354753, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2204.2250633239746, \"count\": 1, \"min\": 2204.2250633239746, \"max\": 2204.2250633239746}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3083.494333344474 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=5, train loss <loss>=0.1844910392537713\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[0] avg_epoch_loss=0.197152\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=0.197151780128479\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[5] avg_epoch_loss=0.242540\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=0.24254039923350015\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch [5]#011Speed: 9940.88 samples/sec#011loss=0.242540\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[10] avg_epoch_loss=0.225940\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=0.20601952970027923\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch [10]#011Speed: 1887.45 samples/sec#011loss=0.206020\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[15] avg_epoch_loss=0.223902\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=0.21941849887371062\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch [15]#011Speed: 9407.96 samples/sec#011loss=0.219418\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[20] avg_epoch_loss=0.215966\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=0.19057140797376632\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch [20]#011Speed: 1827.32 samples/sec#011loss=0.190571\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch[25] avg_epoch_loss=0.199350\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=0.12956450879573822\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:39 INFO 140470849898304] Epoch[6] Batch [25]#011Speed: 10394.08 samples/sec#011loss=0.129565\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[30] avg_epoch_loss=0.191953\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=0.1534833110868931\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [30]#011Speed: 1813.91 samples/sec#011loss=0.153483\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[35] avg_epoch_loss=0.185158\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=0.1430298790335655\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [35]#011Speed: 9917.88 samples/sec#011loss=0.143030\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[40] avg_epoch_loss=0.182440\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=0.16287482678890228\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [40]#011Speed: 1803.79 samples/sec#011loss=0.162875\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[45] avg_epoch_loss=0.180261\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=0.1623869389295578\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [45]#011Speed: 10414.57 samples/sec#011loss=0.162387\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[50] avg_epoch_loss=0.183981\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=0.2182098373770714\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [50]#011Speed: 1865.52 samples/sec#011loss=0.218210\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[55] avg_epoch_loss=0.184688\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=0.1919032007455826\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [55]#011Speed: 10142.12 samples/sec#011loss=0.191903\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[60] avg_epoch_loss=0.184957\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=0.1879640355706215\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [60]#011Speed: 1841.13 samples/sec#011loss=0.187964\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[65] avg_epoch_loss=0.193227\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=0.2941173627972603\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [65]#011Speed: 10134.38 samples/sec#011loss=0.294117\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[70] avg_epoch_loss=0.207576\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=0.3969819962978363\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [70]#011Speed: 1792.07 samples/sec#011loss=0.396982\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch[75] avg_epoch_loss=0.205499\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=0.17601373493671418\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:40 INFO 140470849898304] Epoch[6] Batch [75]#011Speed: 10177.57 samples/sec#011loss=0.176014\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[80] avg_epoch_loss=0.200818\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=0.129661712795496\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [80]#011Speed: 1761.67 samples/sec#011loss=0.129662\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[85] avg_epoch_loss=0.198154\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=0.1549990803003311\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [85]#011Speed: 9872.36 samples/sec#011loss=0.154999\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[90] avg_epoch_loss=0.203982\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=0.304225355386734\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [90]#011Speed: 1808.69 samples/sec#011loss=0.304225\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[95] avg_epoch_loss=0.202421\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=0.17401590347290039\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [95]#011Speed: 10350.40 samples/sec#011loss=0.174016\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[100] avg_epoch_loss=0.200195\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=0.15745301842689513\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [100]#011Speed: 2152.62 samples/sec#011loss=0.157453\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch[105] avg_epoch_loss=0.197720\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=0.14772432446479797\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[6] Batch [105]#011Speed: 11572.39 samples/sec#011loss=0.147724\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] processed a total of 6937 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214799.354815, \"EndTime\": 1711214801.600293, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2245.0644969940186, \"count\": 1, \"min\": 2245.0644969940186, \"max\": 2245.0644969940186}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3089.746225675959 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=6, train loss <loss>=0.19493336763677246\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch[0] avg_epoch_loss=0.470107\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=0.47010719776153564\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch[5] avg_epoch_loss=0.265578\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=0.26557763541738194\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch [5]#011Speed: 9983.39 samples/sec#011loss=0.265578\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch[10] avg_epoch_loss=0.248680\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=0.22840385735034943\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch [10]#011Speed: 1757.71 samples/sec#011loss=0.228404\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch[15] avg_epoch_loss=0.232948\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=0.19833714067935942\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:41 INFO 140470849898304] Epoch[7] Batch [15]#011Speed: 11601.20 samples/sec#011loss=0.198337\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[20] avg_epoch_loss=0.214250\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=0.15441715270280837\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [20]#011Speed: 1860.86 samples/sec#011loss=0.154417\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[25] avg_epoch_loss=0.206241\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=0.1726019410416484\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [25]#011Speed: 11642.25 samples/sec#011loss=0.172602\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[30] avg_epoch_loss=0.186204\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=0.08201007228344678\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [30]#011Speed: 1843.05 samples/sec#011loss=0.082010\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[35] avg_epoch_loss=0.170503\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=0.0731605637818575\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [35]#011Speed: 11913.20 samples/sec#011loss=0.073161\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[40] avg_epoch_loss=0.167106\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=0.14264706447720527\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [40]#011Speed: 1885.49 samples/sec#011loss=0.142647\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[45] avg_epoch_loss=0.168977\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=0.18431364744901657\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [45]#011Speed: 10072.02 samples/sec#011loss=0.184314\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[50] avg_epoch_loss=0.172758\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=0.20754766911268235\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [50]#011Speed: 1831.85 samples/sec#011loss=0.207548\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[55] avg_epoch_loss=0.173049\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=0.17601996436715125\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [55]#011Speed: 10005.35 samples/sec#011loss=0.176020\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch[60] avg_epoch_loss=0.173953\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=0.18407536447048187\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:42 INFO 140470849898304] Epoch[7] Batch [60]#011Speed: 1847.12 samples/sec#011loss=0.184075\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[65] avg_epoch_loss=0.172572\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=0.15572065860033035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [65]#011Speed: 10073.83 samples/sec#011loss=0.155721\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[70] avg_epoch_loss=0.178210\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=0.25263890624046326\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [70]#011Speed: 1837.14 samples/sec#011loss=0.252639\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[75] avg_epoch_loss=0.173362\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=0.10451821237802505\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [75]#011Speed: 10852.98 samples/sec#011loss=0.104518\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[80] avg_epoch_loss=0.173512\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=0.1757834017276764\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [80]#011Speed: 1858.09 samples/sec#011loss=0.175783\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[85] avg_epoch_loss=0.169831\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=0.11019757278263569\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [85]#011Speed: 10196.44 samples/sec#011loss=0.110198\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[90] avg_epoch_loss=0.167382\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=0.12527331113815307\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [90]#011Speed: 1780.12 samples/sec#011loss=0.125273\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[95] avg_epoch_loss=0.170495\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=0.22715069353580475\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [95]#011Speed: 9902.74 samples/sec#011loss=0.227151\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[100] avg_epoch_loss=0.179180\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=0.34593444764614106\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [100]#011Speed: 2162.68 samples/sec#011loss=0.345934\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch[105] avg_epoch_loss=0.179307\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=0.181861774623394\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[7] Batch [105]#011Speed: 10185.06 samples/sec#011loss=0.181862\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] processed a total of 6891 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214801.600364, \"EndTime\": 1711214803.8182518, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2217.4549102783203, \"count\": 1, \"min\": 2217.4549102783203, \"max\": 2217.4549102783203}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3107.4830948664026 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=7, train loss <loss>=0.17709391721075884\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_6dfed26e-c842-49e1-83d6-73c68b9f3688-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214803.8183157, \"EndTime\": 1711214803.8230577, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 4.271984100341797, \"count\": 1, \"min\": 4.271984100341797, \"max\": 4.271984100341797}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[8] Batch[0] avg_epoch_loss=0.155683\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.15568307042121887\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[8] Batch[5] avg_epoch_loss=0.199118\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=0.199118010699749\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:43 INFO 140470849898304] Epoch[8] Batch [5]#011Speed: 11524.50 samples/sec#011loss=0.199118\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[10] avg_epoch_loss=0.190226\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.1795552045106888\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [10]#011Speed: 1843.38 samples/sec#011loss=0.179555\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[15] avg_epoch_loss=0.178859\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=0.1538531079888344\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [15]#011Speed: 11684.42 samples/sec#011loss=0.153853\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[20] avg_epoch_loss=0.200206\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=0.2685135632753372\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [20]#011Speed: 1786.63 samples/sec#011loss=0.268514\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[25] avg_epoch_loss=0.185837\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=0.1254911318421364\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [25]#011Speed: 11654.49 samples/sec#011loss=0.125491\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[30] avg_epoch_loss=0.178194\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=0.13844659477472304\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [30]#011Speed: 1819.00 samples/sec#011loss=0.138447\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[35] avg_epoch_loss=0.167747\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=0.10297449678182602\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [35]#011Speed: 11814.94 samples/sec#011loss=0.102974\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[40] avg_epoch_loss=0.163646\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=0.134120175242424\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [40]#011Speed: 1823.82 samples/sec#011loss=0.134120\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[45] avg_epoch_loss=0.167141\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=0.19579877853393554\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [45]#011Speed: 10696.00 samples/sec#011loss=0.195799\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch[50] avg_epoch_loss=0.167764\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=0.17349344938993455\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:44 INFO 140470849898304] Epoch[8] Batch [50]#011Speed: 1839.76 samples/sec#011loss=0.173493\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[55] avg_epoch_loss=0.171861\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=0.21365994811058045\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [55]#011Speed: 10398.75 samples/sec#011loss=0.213660\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[60] avg_epoch_loss=0.170391\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=0.15391613095998763\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [60]#011Speed: 1815.43 samples/sec#011loss=0.153916\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[65] avg_epoch_loss=0.172987\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=0.2046687960624695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [65]#011Speed: 10066.13 samples/sec#011loss=0.204669\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[70] avg_epoch_loss=0.176080\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=0.21689601391553878\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [70]#011Speed: 1769.83 samples/sec#011loss=0.216896\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[75] avg_epoch_loss=0.172552\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=0.1224640280008316\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [75]#011Speed: 9830.28 samples/sec#011loss=0.122464\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[80] avg_epoch_loss=0.168750\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=0.11096086055040359\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [80]#011Speed: 1835.61 samples/sec#011loss=0.110961\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[85] avg_epoch_loss=0.168771\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=0.1690988138318062\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [85]#011Speed: 10175.26 samples/sec#011loss=0.169099\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[90] avg_epoch_loss=0.169137\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=0.17543595731258393\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [90]#011Speed: 1802.00 samples/sec#011loss=0.175436\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch[95] avg_epoch_loss=0.167863\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=0.14468113481998443\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:45 INFO 140470849898304] Epoch[8] Batch [95]#011Speed: 10302.01 samples/sec#011loss=0.144681\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[8] Batch[100] avg_epoch_loss=0.172636\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=0.26427687108516695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[8] Batch [100]#011Speed: 2041.56 samples/sec#011loss=0.264277\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[8] Batch[105] avg_epoch_loss=0.173786\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=0.19701080471277238\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[8] Batch [105]#011Speed: 9920.38 samples/sec#011loss=0.197011\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] processed a total of 6944 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214803.8231153, \"EndTime\": 1711214806.0622923, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2239.129066467285, \"count\": 1, \"min\": 2239.129066467285, \"max\": 2239.129066467285}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3101.068747103254 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=8, train loss <loss>=0.17043851490277762\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_3debe6d2-26fd-4c91-aad2-02a37e1ef1bb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214806.0623631, \"EndTime\": 1711214806.0667348, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 3.887653350830078, \"count\": 1, \"min\": 3.887653350830078, \"max\": 3.887653350830078}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[0] avg_epoch_loss=0.250267\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.2502669394016266\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[5] avg_epoch_loss=0.180088\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.18008821892241636\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [5]#011Speed: 10030.92 samples/sec#011loss=0.180088\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[10] avg_epoch_loss=0.189716\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.20127029418945314\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [10]#011Speed: 1813.91 samples/sec#011loss=0.201270\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[15] avg_epoch_loss=0.186190\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=0.17843060493469237\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [15]#011Speed: 10256.20 samples/sec#011loss=0.178431\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[20] avg_epoch_loss=0.195358\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=0.22469790875911713\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [20]#011Speed: 1785.40 samples/sec#011loss=0.224698\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[25] avg_epoch_loss=0.175820\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=0.09375677406787872\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [25]#011Speed: 11659.35 samples/sec#011loss=0.093757\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[30] avg_epoch_loss=0.160687\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=0.0819952704012394\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [30]#011Speed: 1696.65 samples/sec#011loss=0.081995\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch[35] avg_epoch_loss=0.170879\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=0.2340689331293106\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:46 INFO 140470849898304] Epoch[9] Batch [35]#011Speed: 9715.08 samples/sec#011loss=0.234069\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[40] avg_epoch_loss=0.166815\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=0.1375570997595787\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [40]#011Speed: 1803.72 samples/sec#011loss=0.137557\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[45] avg_epoch_loss=0.167803\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=0.1759008303284645\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [45]#011Speed: 10275.28 samples/sec#011loss=0.175901\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[50] avg_epoch_loss=0.169312\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=0.18319771960377693\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [50]#011Speed: 1904.62 samples/sec#011loss=0.183198\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[55] avg_epoch_loss=0.165111\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=0.12226717919111252\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [55]#011Speed: 10516.08 samples/sec#011loss=0.122267\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[60] avg_epoch_loss=0.162243\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=0.13011403977870942\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [60]#011Speed: 1842.63 samples/sec#011loss=0.130114\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[65] avg_epoch_loss=0.161637\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=0.15424305349588394\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [65]#011Speed: 10292.93 samples/sec#011loss=0.154243\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[70] avg_epoch_loss=0.158946\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=0.12342387065291405\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [70]#011Speed: 1860.39 samples/sec#011loss=0.123424\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[75] avg_epoch_loss=0.164853\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=0.24873829185962676\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [75]#011Speed: 11419.29 samples/sec#011loss=0.248738\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[80] avg_epoch_loss=0.165096\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=0.16878494918346404\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [80]#011Speed: 1730.67 samples/sec#011loss=0.168785\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch[85] avg_epoch_loss=0.164118\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=0.14826879501342774\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:47 INFO 140470849898304] Epoch[9] Batch [85]#011Speed: 10123.07 samples/sec#011loss=0.148269\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch[90] avg_epoch_loss=0.162586\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=0.13624444603919983\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch [90]#011Speed: 1820.18 samples/sec#011loss=0.136244\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch[95] avg_epoch_loss=0.161678\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=0.14515307247638704\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch [95]#011Speed: 9977.08 samples/sec#011loss=0.145153\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch[100] avg_epoch_loss=0.162173\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=0.17167588397860528\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch [100]#011Speed: 2227.01 samples/sec#011loss=0.171676\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch[105] avg_epoch_loss=0.158761\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=0.08984197154641152\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[9] Batch [105]#011Speed: 10452.28 samples/sec#011loss=0.089842\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] processed a total of 6898 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214806.066795, \"EndTime\": 1711214808.3137317, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2246.886968612671, \"count\": 1, \"min\": 2246.886968612671, \"max\": 2246.886968612671}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3069.8967005435393 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=9, train loss <loss>=0.16022817280005525\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_c23ec874-219f-459b-b8ed-9173a1428781-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214808.3137965, \"EndTime\": 1711214808.3185132, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 4.273176193237305, \"count\": 1, \"min\": 4.273176193237305, \"max\": 4.273176193237305}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[0] avg_epoch_loss=0.370852\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.3708524703979492\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[5] avg_epoch_loss=0.250265\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.25026492526133853\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch [5]#011Speed: 10076.48 samples/sec#011loss=0.250265\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[10] avg_epoch_loss=0.265641\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.2840913593769073\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch [10]#011Speed: 1822.69 samples/sec#011loss=0.284091\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[15] avg_epoch_loss=0.272424\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=0.2873466402292252\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch [15]#011Speed: 10274.33 samples/sec#011loss=0.287347\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[20] avg_epoch_loss=0.270861\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=0.26585893034935\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch [20]#011Speed: 1811.41 samples/sec#011loss=0.265859\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch[25] avg_epoch_loss=0.240372\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=0.11231958866119385\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:48 INFO 140470849898304] Epoch[10] Batch [25]#011Speed: 10371.43 samples/sec#011loss=0.112320\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[30] avg_epoch_loss=0.219596\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=0.11155986897647381\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [30]#011Speed: 1798.09 samples/sec#011loss=0.111560\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[35] avg_epoch_loss=0.208487\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=0.13961136490106582\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [35]#011Speed: 10015.05 samples/sec#011loss=0.139611\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[40] avg_epoch_loss=0.203502\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=0.1676110953092575\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [40]#011Speed: 1797.62 samples/sec#011loss=0.167611\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[45] avg_epoch_loss=0.200732\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=0.178021377325058\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [45]#011Speed: 10054.89 samples/sec#011loss=0.178021\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[50] avg_epoch_loss=0.197846\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=0.1712953343987465\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [50]#011Speed: 1747.66 samples/sec#011loss=0.171295\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[55] avg_epoch_loss=0.194262\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=0.15770115852355956\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [55]#011Speed: 10645.78 samples/sec#011loss=0.157701\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[60] avg_epoch_loss=0.189288\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=0.13358221538364887\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [60]#011Speed: 1856.71 samples/sec#011loss=0.133582\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[65] avg_epoch_loss=0.188297\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=0.17620717883110046\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [65]#011Speed: 9750.44 samples/sec#011loss=0.176207\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[70] avg_epoch_loss=0.191112\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=0.22826463729143143\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [70]#011Speed: 1792.28 samples/sec#011loss=0.228265\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch[75] avg_epoch_loss=0.193067\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=0.2208266794681549\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:49 INFO 140470849898304] Epoch[10] Batch [75]#011Speed: 10282.20 samples/sec#011loss=0.220827\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[80] avg_epoch_loss=0.192720\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=0.18744900524616243\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [80]#011Speed: 1767.41 samples/sec#011loss=0.187449\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[85] avg_epoch_loss=0.200660\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=0.32928021550178527\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [85]#011Speed: 10322.93 samples/sec#011loss=0.329280\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[90] avg_epoch_loss=0.195008\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=0.09780860617756844\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [90]#011Speed: 1808.09 samples/sec#011loss=0.097809\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[95] avg_epoch_loss=0.191081\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=0.11960443407297135\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [95]#011Speed: 10093.08 samples/sec#011loss=0.119604\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[100] avg_epoch_loss=0.187737\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=0.12352193966507911\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [100]#011Speed: 2934.63 samples/sec#011loss=0.123522\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch[105] avg_epoch_loss=0.183825\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=0.10480497777462006\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[10] Batch [105]#011Speed: 9831.07 samples/sec#011loss=0.104805\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] processed a total of 6760 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214808.3185706, \"EndTime\": 1711214810.5261233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2207.5035572052, \"count\": 1, \"min\": 2207.5035572052, \"max\": 2207.5035572052}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3062.114384763674 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=10, train loss <loss>=0.18382474140457386\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch[0] avg_epoch_loss=0.180656\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=0.18065600097179413\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch[5] avg_epoch_loss=0.218201\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.21820075189073881\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch [5]#011Speed: 11182.39 samples/sec#011loss=0.218201\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch[10] avg_epoch_loss=0.178225\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=0.13025469779968263\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch [10]#011Speed: 1848.98 samples/sec#011loss=0.130255\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch[15] avg_epoch_loss=0.212658\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=0.2884113095700741\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:50 INFO 140470849898304] Epoch[11] Batch [15]#011Speed: 11578.58 samples/sec#011loss=0.288411\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[20] avg_epoch_loss=0.217750\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=0.2340418964624405\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [20]#011Speed: 1914.00 samples/sec#011loss=0.234042\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[25] avg_epoch_loss=0.204327\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=0.14795287251472472\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [25]#011Speed: 11390.60 samples/sec#011loss=0.147953\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[30] avg_epoch_loss=0.182700\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=0.07023903355002403\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [30]#011Speed: 1917.08 samples/sec#011loss=0.070239\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[35] avg_epoch_loss=0.175199\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=0.12869009375572205\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [35]#011Speed: 11877.89 samples/sec#011loss=0.128690\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[40] avg_epoch_loss=0.167791\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=0.11445504389703273\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [40]#011Speed: 1878.78 samples/sec#011loss=0.114455\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[45] avg_epoch_loss=0.172955\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=0.21529991328716278\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [45]#011Speed: 11603.91 samples/sec#011loss=0.215300\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[50] avg_epoch_loss=0.174704\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=0.19079624265432357\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [50]#011Speed: 1888.66 samples/sec#011loss=0.190796\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[55] avg_epoch_loss=0.170622\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=0.12898229956626892\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [55]#011Speed: 11838.49 samples/sec#011loss=0.128982\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[60] avg_epoch_loss=0.172744\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=0.19651462733745576\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [60]#011Speed: 1935.49 samples/sec#011loss=0.196515\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch[65] avg_epoch_loss=0.174480\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=0.19566183686256408\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:51 INFO 140470849898304] Epoch[11] Batch [65]#011Speed: 11670.80 samples/sec#011loss=0.195662\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[70] avg_epoch_loss=0.179467\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=0.24529469460248948\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [70]#011Speed: 1801.77 samples/sec#011loss=0.245295\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[75] avg_epoch_loss=0.176261\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=0.13073010742664337\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [75]#011Speed: 10875.49 samples/sec#011loss=0.130730\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[80] avg_epoch_loss=0.176921\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=0.18695977777242662\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [80]#011Speed: 1850.29 samples/sec#011loss=0.186960\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[85] avg_epoch_loss=0.173810\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=0.12341030687093735\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [85]#011Speed: 11707.96 samples/sec#011loss=0.123410\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[90] avg_epoch_loss=0.171246\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=0.1271453969180584\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [90]#011Speed: 1836.41 samples/sec#011loss=0.127145\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[95] avg_epoch_loss=0.168591\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=0.12027359753847122\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [95]#011Speed: 11793.14 samples/sec#011loss=0.120274\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[100] avg_epoch_loss=0.172614\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=0.24984960854053498\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [100]#011Speed: 2304.06 samples/sec#011loss=0.249850\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch[105] avg_epoch_loss=0.170042\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=0.1180929459631443\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[11] Batch [105]#011Speed: 11734.99 samples/sec#011loss=0.118093\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] processed a total of 6894 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214810.5262158, \"EndTime\": 1711214812.67262, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2146.0137367248535, \"count\": 1, \"min\": 2146.0137367248535, \"max\": 2146.0137367248535}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3212.33645336582 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=11, train loss <loss>=0.16829241889839372\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[12] Batch[0] avg_epoch_loss=0.287432\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=0.2874321937561035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[12] Batch[5] avg_epoch_loss=0.217428\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=0.2174282173315684\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:52 INFO 140470849898304] Epoch[12] Batch [5]#011Speed: 10225.49 samples/sec#011loss=0.217428\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[10] avg_epoch_loss=0.262271\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=0.3160813868045807\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [10]#011Speed: 1886.84 samples/sec#011loss=0.316081\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[15] avg_epoch_loss=0.245083\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=0.20727145224809645\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [15]#011Speed: 11660.97 samples/sec#011loss=0.207271\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[20] avg_epoch_loss=0.231421\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=0.1877026677131653\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [20]#011Speed: 1874.96 samples/sec#011loss=0.187703\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[25] avg_epoch_loss=0.213234\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=0.13684856593608857\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [25]#011Speed: 11637.31 samples/sec#011loss=0.136849\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[30] avg_epoch_loss=0.208683\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=0.1850157395005226\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [30]#011Speed: 1857.02 samples/sec#011loss=0.185016\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[35] avg_epoch_loss=0.193216\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=0.09731897823512554\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [35]#011Speed: 11857.74 samples/sec#011loss=0.097319\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[40] avg_epoch_loss=0.181978\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=0.10106350928544998\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [40]#011Speed: 1792.22 samples/sec#011loss=0.101064\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[45] avg_epoch_loss=0.177854\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=0.14404304176568986\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [45]#011Speed: 10084.28 samples/sec#011loss=0.144043\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[50] avg_epoch_loss=0.179400\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=0.19362348467111587\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [50]#011Speed: 1767.74 samples/sec#011loss=0.193623\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch[55] avg_epoch_loss=0.168926\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=0.06208456382155418\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:53 INFO 140470849898304] Epoch[12] Batch [55]#011Speed: 10372.39 samples/sec#011loss=0.062085\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[60] avg_epoch_loss=0.165510\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=0.12725657299160958\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [60]#011Speed: 1814.91 samples/sec#011loss=0.127257\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[65] avg_epoch_loss=0.164343\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=0.15009953081607819\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [65]#011Speed: 10017.52 samples/sec#011loss=0.150100\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[70] avg_epoch_loss=0.168718\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=0.22646795809268952\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [70]#011Speed: 1691.09 samples/sec#011loss=0.226468\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[75] avg_epoch_loss=0.172497\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=0.2261652171611786\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [75]#011Speed: 9211.61 samples/sec#011loss=0.226165\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[80] avg_epoch_loss=0.176891\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=0.24367334842681884\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [80]#011Speed: 1733.31 samples/sec#011loss=0.243673\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[85] avg_epoch_loss=0.173384\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=0.11657617390155792\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [85]#011Speed: 10110.72 samples/sec#011loss=0.116576\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[90] avg_epoch_loss=0.168994\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=0.09348014742136002\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [90]#011Speed: 1857.39 samples/sec#011loss=0.093480\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[95] avg_epoch_loss=0.166689\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=0.12473366409540176\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [95]#011Speed: 10494.20 samples/sec#011loss=0.124734\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[100] avg_epoch_loss=0.167424\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=0.18153584748506546\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [100]#011Speed: 2642.31 samples/sec#011loss=0.181536\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch[105] avg_epoch_loss=0.164549\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=0.10649270415306092\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] Epoch[12] Batch [105]#011Speed: 10801.28 samples/sec#011loss=0.106493\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] processed a total of 6800 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214812.6726794, \"EndTime\": 1711214814.8770661, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2204.0867805480957, \"count\": 1, \"min\": 2204.0867805480957, \"max\": 2204.0867805480957}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3085.0561737592584 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] #quality_metric: host=algo-1, epoch=12, train loss <loss>=0.16301160819271457\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:54 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[0] avg_epoch_loss=0.306197\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=0.30619651079177856\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[5] avg_epoch_loss=0.283894\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=0.28389374911785126\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [5]#011Speed: 8564.72 samples/sec#011loss=0.283894\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[10] avg_epoch_loss=0.244953\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=0.1982240468263626\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [10]#011Speed: 1797.56 samples/sec#011loss=0.198224\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[15] avg_epoch_loss=0.205099\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=0.11741867065429687\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [15]#011Speed: 10164.01 samples/sec#011loss=0.117419\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[20] avg_epoch_loss=0.201744\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=0.1910077750682831\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [20]#011Speed: 1859.26 samples/sec#011loss=0.191008\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[25] avg_epoch_loss=0.186621\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=0.12310439497232437\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [25]#011Speed: 10223.70 samples/sec#011loss=0.123104\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[30] avg_epoch_loss=0.171033\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=0.08997779041528702\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [30]#011Speed: 1801.59 samples/sec#011loss=0.089978\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[35] avg_epoch_loss=0.161523\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=0.10255794674158096\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [35]#011Speed: 9207.31 samples/sec#011loss=0.102558\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[40] avg_epoch_loss=0.157581\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=0.12920273691415787\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [40]#011Speed: 1765.50 samples/sec#011loss=0.129203\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch[45] avg_epoch_loss=0.155983\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=0.14287385493516921\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:55 INFO 140470849898304] Epoch[13] Batch [45]#011Speed: 8527.01 samples/sec#011loss=0.142874\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[50] avg_epoch_loss=0.156179\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=0.15798773169517516\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [50]#011Speed: 1707.16 samples/sec#011loss=0.157988\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[55] avg_epoch_loss=0.155824\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=0.15220645368099212\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [55]#011Speed: 10761.52 samples/sec#011loss=0.152206\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[60] avg_epoch_loss=0.150785\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=0.09434436596930026\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [60]#011Speed: 1891.83 samples/sec#011loss=0.094344\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[65] avg_epoch_loss=0.151561\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=0.16103219389915466\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [65]#011Speed: 11063.85 samples/sec#011loss=0.161032\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[70] avg_epoch_loss=0.156973\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=0.22840735465288162\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [70]#011Speed: 1848.36 samples/sec#011loss=0.228407\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[75] avg_epoch_loss=0.153005\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=0.09666210263967515\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [75]#011Speed: 11285.63 samples/sec#011loss=0.096662\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[80] avg_epoch_loss=0.151804\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=0.133540341258049\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [80]#011Speed: 1860.81 samples/sec#011loss=0.133540\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[85] avg_epoch_loss=0.146734\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=0.0646021194756031\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [85]#011Speed: 11757.91 samples/sec#011loss=0.064602\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[90] avg_epoch_loss=0.146573\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=0.1438061401247978\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [90]#011Speed: 1872.60 samples/sec#011loss=0.143806\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch[95] avg_epoch_loss=0.147123\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=0.15713350772857665\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:56 INFO 140470849898304] Epoch[13] Batch [95]#011Speed: 9813.25 samples/sec#011loss=0.157134\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[13] Batch[100] avg_epoch_loss=0.146323\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=0.13096489943563938\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[13] Batch [100]#011Speed: 2380.52 samples/sec#011loss=0.130965\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[13] Batch[105] avg_epoch_loss=0.143136\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=0.07876611575484276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[13] Batch [105]#011Speed: 10120.09 samples/sec#011loss=0.078766\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] processed a total of 6809 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214814.877126, \"EndTime\": 1711214817.1034272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2225.992441177368, \"count\": 1, \"min\": 2225.992441177368, \"max\": 2225.992441177368}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3058.717832125441 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=13, train loss <loss>=0.14202202652868268\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/state_60238e25-a708-45a3-9bfe-e0048b750342-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214817.1034987, \"EndTime\": 1711214817.1080785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 4.123449325561523, \"count\": 1, \"min\": 4.123449325561523, \"max\": 4.123449325561523}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[0] avg_epoch_loss=0.438215\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=0.4382147789001465\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[5] avg_epoch_loss=0.264738\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=0.26473771408200264\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [5]#011Speed: 10335.81 samples/sec#011loss=0.264738\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[10] avg_epoch_loss=0.283177\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=0.3053044408559799\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [10]#011Speed: 1824.79 samples/sec#011loss=0.305304\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[15] avg_epoch_loss=0.225846\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=0.09971619546413421\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [15]#011Speed: 10123.91 samples/sec#011loss=0.099716\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[20] avg_epoch_loss=0.201349\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=0.12296018600463868\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [20]#011Speed: 1772.39 samples/sec#011loss=0.122960\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[25] avg_epoch_loss=0.174589\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=0.062194832414388654\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [25]#011Speed: 10728.41 samples/sec#011loss=0.062195\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[30] avg_epoch_loss=0.167144\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=0.12842957079410552\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [30]#011Speed: 1806.88 samples/sec#011loss=0.128430\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch[35] avg_epoch_loss=0.161712\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=0.12803757488727568\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:57 INFO 140470849898304] Epoch[14] Batch [35]#011Speed: 11083.21 samples/sec#011loss=0.128038\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[40] avg_epoch_loss=0.153710\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=0.09609101265668869\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [40]#011Speed: 1731.21 samples/sec#011loss=0.096091\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[45] avg_epoch_loss=0.162124\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=0.23112514317035676\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [45]#011Speed: 9232.01 samples/sec#011loss=0.231125\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[50] avg_epoch_loss=0.164890\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=0.1903378561139107\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [50]#011Speed: 1891.47 samples/sec#011loss=0.190338\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[55] avg_epoch_loss=0.161044\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=0.12181247174739837\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [55]#011Speed: 10098.09 samples/sec#011loss=0.121812\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[60] avg_epoch_loss=0.160360\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=0.1526985362172127\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [60]#011Speed: 1856.60 samples/sec#011loss=0.152699\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[65] avg_epoch_loss=0.178741\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=0.4029917001724243\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [65]#011Speed: 11551.57 samples/sec#011loss=0.402992\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[70] avg_epoch_loss=0.177901\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=0.16680838465690612\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [70]#011Speed: 1800.98 samples/sec#011loss=0.166808\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[75] avg_epoch_loss=0.175179\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=0.13652507066726685\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [75]#011Speed: 11773.07 samples/sec#011loss=0.136525\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[80] avg_epoch_loss=0.180834\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=0.26678860783576963\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [80]#011Speed: 1863.30 samples/sec#011loss=0.266789\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch[85] avg_epoch_loss=0.181047\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=0.18449411690235137\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:58 INFO 140470849898304] Epoch[14] Batch [85]#011Speed: 10801.28 samples/sec#011loss=0.184494\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch[90] avg_epoch_loss=0.176979\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=0.10701214019209146\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch [90]#011Speed: 1860.74 samples/sec#011loss=0.107012\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch[95] avg_epoch_loss=0.174687\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=0.13297869712114335\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch [95]#011Speed: 11763.48 samples/sec#011loss=0.132979\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch[100] avg_epoch_loss=0.190768\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=0.4995275489985943\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch [100]#011Speed: 2606.64 samples/sec#011loss=0.499528\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch[105] avg_epoch_loss=0.191462\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=0.20547218918800353\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[14] Batch [105]#011Speed: 11849.78 samples/sec#011loss=0.205472\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] processed a total of 6822 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214817.1081367, \"EndTime\": 1711214819.3007677, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2192.582845687866, \"count\": 1, \"min\": 2192.582845687866, \"max\": 2192.582845687866}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3111.2754811387185 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=14, train loss <loss>=0.18983316505937098\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[0] avg_epoch_loss=0.233676\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=0.23367562890052795\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[5] avg_epoch_loss=0.215291\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=0.2152914193769296\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch [5]#011Speed: 10379.21 samples/sec#011loss=0.215291\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[10] avg_epoch_loss=0.217420\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=0.2199737846851349\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch [10]#011Speed: 1849.17 samples/sec#011loss=0.219974\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[15] avg_epoch_loss=0.215276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=0.21055941581726073\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch [15]#011Speed: 10496.83 samples/sec#011loss=0.210559\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[20] avg_epoch_loss=0.187940\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=0.10046635270118713\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch [20]#011Speed: 1844.38 samples/sec#011loss=0.100466\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch[25] avg_epoch_loss=0.166301\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=0.07541681490838528\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:26:59 INFO 140470849898304] Epoch[15] Batch [25]#011Speed: 10458.80 samples/sec#011loss=0.075417\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[30] avg_epoch_loss=0.176461\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=0.2292891636490822\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [30]#011Speed: 1878.28 samples/sec#011loss=0.229289\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[35] avg_epoch_loss=0.170865\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=0.13617093712091446\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [35]#011Speed: 10263.57 samples/sec#011loss=0.136171\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[40] avg_epoch_loss=0.168474\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=0.15126223117113113\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [40]#011Speed: 1793.03 samples/sec#011loss=0.151262\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[45] avg_epoch_loss=0.173799\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=0.21746067106723785\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [45]#011Speed: 10339.47 samples/sec#011loss=0.217461\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[50] avg_epoch_loss=0.181505\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=0.2524065047502518\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [50]#011Speed: 1882.25 samples/sec#011loss=0.252407\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[55] avg_epoch_loss=0.174713\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=0.10542502328753471\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [55]#011Speed: 11717.57 samples/sec#011loss=0.105425\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[60] avg_epoch_loss=0.173301\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=0.15748778432607652\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [60]#011Speed: 1811.73 samples/sec#011loss=0.157488\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[65] avg_epoch_loss=0.180607\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=0.26974698305130007\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [65]#011Speed: 11521.23 samples/sec#011loss=0.269747\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[70] avg_epoch_loss=0.188532\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=0.2931362435221672\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [70]#011Speed: 1892.26 samples/sec#011loss=0.293136\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch[75] avg_epoch_loss=0.190988\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=0.22587043344974517\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:00 INFO 140470849898304] Epoch[15] Batch [75]#011Speed: 11715.52 samples/sec#011loss=0.225870\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[80] avg_epoch_loss=0.193082\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=0.22491328716278075\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [80]#011Speed: 1572.57 samples/sec#011loss=0.224913\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[85] avg_epoch_loss=0.189035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=0.12346579134464264\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [85]#011Speed: 11072.61 samples/sec#011loss=0.123466\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[90] avg_epoch_loss=0.186578\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=0.14431737512350082\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [90]#011Speed: 1766.27 samples/sec#011loss=0.144317\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[95] avg_epoch_loss=0.183257\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=0.12281624898314476\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [95]#011Speed: 9061.11 samples/sec#011loss=0.122816\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[100] avg_epoch_loss=0.181638\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=0.15055691748857497\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [100]#011Speed: 1991.97 samples/sec#011loss=0.150557\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch[105] avg_epoch_loss=0.180580\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=0.15920885056257247\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[15] Batch [105]#011Speed: 8181.36 samples/sec#011loss=0.159209\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] processed a total of 6959 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214819.300827, \"EndTime\": 1711214821.6173139, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2316.204786300659, \"count\": 1, \"min\": 2316.204786300659, \"max\": 2316.204786300659}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3004.3462871804836 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=15, train loss <loss>=0.18031776988656695\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[16] Batch[0] avg_epoch_loss=0.323521\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=0.3235207796096802\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[16] Batch[5] avg_epoch_loss=0.285415\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.28541504964232445\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:01 INFO 140470849898304] Epoch[16] Batch [5]#011Speed: 8601.11 samples/sec#011loss=0.285415\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[10] avg_epoch_loss=0.257752\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=0.22455563992261887\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [10]#011Speed: 1675.93 samples/sec#011loss=0.224556\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[15] avg_epoch_loss=0.231185\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=0.17273957282304764\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [15]#011Speed: 6838.14 samples/sec#011loss=0.172740\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[20] avg_epoch_loss=0.213247\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=0.1558436669409275\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [20]#011Speed: 1429.95 samples/sec#011loss=0.155844\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[25] avg_epoch_loss=0.180685\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=0.04392705596983433\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [25]#011Speed: 7251.95 samples/sec#011loss=0.043927\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[30] avg_epoch_loss=0.175280\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=0.1471744328737259\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [30]#011Speed: 1418.19 samples/sec#011loss=0.147174\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[35] avg_epoch_loss=0.178500\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=0.19846434965729715\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [35]#011Speed: 6182.02 samples/sec#011loss=0.198464\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[40] avg_epoch_loss=0.172363\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=0.12817006707191467\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [40]#011Speed: 1241.04 samples/sec#011loss=0.128170\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch[45] avg_epoch_loss=0.166007\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=0.11389364898204804\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:02 INFO 140470849898304] Epoch[16] Batch [45]#011Speed: 7341.40 samples/sec#011loss=0.113894\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[50] avg_epoch_loss=0.163530\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=0.1407402992248535\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [50]#011Speed: 1770.20 samples/sec#011loss=0.140740\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[55] avg_epoch_loss=0.162372\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=0.1505628004670143\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [55]#011Speed: 11223.81 samples/sec#011loss=0.150563\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[60] avg_epoch_loss=0.159487\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=0.127169668674469\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [60]#011Speed: 1956.07 samples/sec#011loss=0.127170\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[65] avg_epoch_loss=0.164566\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=0.22653342485427858\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [65]#011Speed: 11566.61 samples/sec#011loss=0.226533\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[70] avg_epoch_loss=0.167952\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=0.2126458019018173\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [70]#011Speed: 1865.06 samples/sec#011loss=0.212646\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[75] avg_epoch_loss=0.171900\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=0.22795632779598235\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [75]#011Speed: 11308.35 samples/sec#011loss=0.227956\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[80] avg_epoch_loss=0.168153\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=0.11120494455099106\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [80]#011Speed: 1855.58 samples/sec#011loss=0.111205\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[85] avg_epoch_loss=0.165331\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=0.11961797401309013\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [85]#011Speed: 11372.94 samples/sec#011loss=0.119618\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[90] avg_epoch_loss=0.162010\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=0.1048788383603096\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [90]#011Speed: 1859.25 samples/sec#011loss=0.104879\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch[95] avg_epoch_loss=0.162191\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=0.1654861956834793\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:03 INFO 140470849898304] Epoch[16] Batch [95]#011Speed: 9823.30 samples/sec#011loss=0.165486\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[16] Batch[100] avg_epoch_loss=0.164284\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=0.20446814969182014\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[16] Batch [100]#011Speed: 2354.56 samples/sec#011loss=0.204468\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[16] Batch[105] avg_epoch_loss=0.161503\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=0.1053297683596611\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[16] Batch [105]#011Speed: 11494.20 samples/sec#011loss=0.105330\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] processed a total of 6904 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214821.6173854, \"EndTime\": 1711214824.0886579, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2470.8199501037598, \"count\": 1, \"min\": 2470.8199501037598, \"max\": 2470.8199501037598}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=2794.1108608049612 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=16, train loss <loss>=0.1611674378488075\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[0] avg_epoch_loss=0.315510\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=0.3155098855495453\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[5] avg_epoch_loss=0.297608\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=0.2976078540086746\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [5]#011Speed: 11560.13 samples/sec#011loss=0.297608\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[10] avg_epoch_loss=0.354444\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=0.42264628410339355\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [10]#011Speed: 1765.40 samples/sec#011loss=0.422646\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[15] avg_epoch_loss=0.304278\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=0.19391437768936157\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [15]#011Speed: 9737.42 samples/sec#011loss=0.193914\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[20] avg_epoch_loss=0.278328\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=0.1952855631709099\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [20]#011Speed: 1812.28 samples/sec#011loss=0.195286\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[25] avg_epoch_loss=0.243673\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=0.09812373667955399\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [25]#011Speed: 10215.45 samples/sec#011loss=0.098124\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[30] avg_epoch_loss=0.223959\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=0.12144778408110142\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [30]#011Speed: 1800.60 samples/sec#011loss=0.121448\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch[35] avg_epoch_loss=0.212997\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=0.14503017961978912\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:04 INFO 140470849898304] Epoch[17] Batch [35]#011Speed: 9796.56 samples/sec#011loss=0.145030\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[40] avg_epoch_loss=0.206613\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=0.16064833104610443\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [40]#011Speed: 1841.35 samples/sec#011loss=0.160648\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[45] avg_epoch_loss=0.202478\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=0.1685725510120392\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [45]#011Speed: 10034.15 samples/sec#011loss=0.168573\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[50] avg_epoch_loss=0.201388\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=0.19135694056749344\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [50]#011Speed: 1794.23 samples/sec#011loss=0.191357\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[55] avg_epoch_loss=0.192304\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=0.09964959025382995\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [55]#011Speed: 10271.50 samples/sec#011loss=0.099650\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[60] avg_epoch_loss=0.189035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=0.15242250859737397\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [60]#011Speed: 1811.76 samples/sec#011loss=0.152423\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[65] avg_epoch_loss=0.197544\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=0.3013566792011261\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [65]#011Speed: 9835.03 samples/sec#011loss=0.301357\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[70] avg_epoch_loss=0.202221\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=0.2639592349529266\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [70]#011Speed: 1825.86 samples/sec#011loss=0.263959\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[75] avg_epoch_loss=0.201342\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=0.18885082006454468\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [75]#011Speed: 9960.43 samples/sec#011loss=0.188851\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[80] avg_epoch_loss=0.203006\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=0.22830927073955537\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [80]#011Speed: 1815.79 samples/sec#011loss=0.228309\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch[85] avg_epoch_loss=0.204569\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=0.2298799991607666\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:05 INFO 140470849898304] Epoch[17] Batch [85]#011Speed: 9462.08 samples/sec#011loss=0.229880\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch[90] avg_epoch_loss=0.200816\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=0.136273193359375\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch [90]#011Speed: 1866.29 samples/sec#011loss=0.136273\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch[95] avg_epoch_loss=0.197683\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=0.14065631330013276\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch [95]#011Speed: 11742.07 samples/sec#011loss=0.140656\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch[100] avg_epoch_loss=0.195801\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=0.15967446342110633\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch [100]#011Speed: 2173.66 samples/sec#011loss=0.159674\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch[105] avg_epoch_loss=0.192449\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=0.1247251108288765\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[17] Batch [105]#011Speed: 11734.06 samples/sec#011loss=0.124725\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] processed a total of 6941 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214824.0887194, \"EndTime\": 1711214826.3375983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2248.589038848877, \"count\": 1, \"min\": 2248.589038848877, \"max\": 2248.589038848877}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3086.7048315710367 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=17, train loss <loss>=0.1903204059894752\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[0] avg_epoch_loss=0.185465\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=0.18546496331691742\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[5] avg_epoch_loss=0.280683\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=0.2806830046077569\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch [5]#011Speed: 11145.52 samples/sec#011loss=0.280683\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[10] avg_epoch_loss=0.253191\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=0.2202008068561554\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch [10]#011Speed: 1849.13 samples/sec#011loss=0.220201\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[15] avg_epoch_loss=0.217074\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=0.1376162961125374\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch [15]#011Speed: 11266.21 samples/sec#011loss=0.137616\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[20] avg_epoch_loss=0.214513\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=0.20631797090172768\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch [20]#011Speed: 1897.81 samples/sec#011loss=0.206318\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch[25] avg_epoch_loss=0.188217\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=0.07777408491820097\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:06 INFO 140470849898304] Epoch[18] Batch [25]#011Speed: 11552.97 samples/sec#011loss=0.077774\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[30] avg_epoch_loss=0.174784\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=0.10493435524404049\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [30]#011Speed: 1706.19 samples/sec#011loss=0.104934\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[35] avg_epoch_loss=0.164527\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=0.10093471556901931\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [35]#011Speed: 9946.18 samples/sec#011loss=0.100935\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[40] avg_epoch_loss=0.163214\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=0.15375698506832122\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [40]#011Speed: 1815.22 samples/sec#011loss=0.153757\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[45] avg_epoch_loss=0.160399\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=0.1373164877295494\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [45]#011Speed: 10370.63 samples/sec#011loss=0.137316\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[50] avg_epoch_loss=0.158114\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=0.13709589391946791\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [50]#011Speed: 1775.88 samples/sec#011loss=0.137096\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[55] avg_epoch_loss=0.151946\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=0.08902677968144417\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [55]#011Speed: 10877.26 samples/sec#011loss=0.089027\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[60] avg_epoch_loss=0.151013\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=0.14056505933403968\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [60]#011Speed: 1821.44 samples/sec#011loss=0.140565\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[65] avg_epoch_loss=0.150164\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=0.1398061715066433\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [65]#011Speed: 10412.63 samples/sec#011loss=0.139806\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[70] avg_epoch_loss=0.157244\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=0.25069413483142855\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [70]#011Speed: 1788.56 samples/sec#011loss=0.250694\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch[75] avg_epoch_loss=0.161347\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=0.21960767209529877\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:07 INFO 140470849898304] Epoch[18] Batch [75]#011Speed: 8864.40 samples/sec#011loss=0.219608\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[80] avg_epoch_loss=0.159951\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=0.13874287977814675\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [80]#011Speed: 1849.25 samples/sec#011loss=0.138743\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[85] avg_epoch_loss=0.155088\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=0.07630268298089504\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [85]#011Speed: 10356.71 samples/sec#011loss=0.076303\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[90] avg_epoch_loss=0.156013\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=0.1719156965613365\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [90]#011Speed: 1830.08 samples/sec#011loss=0.171916\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[95] avg_epoch_loss=0.155232\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=0.14102303832769394\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [95]#011Speed: 10128.95 samples/sec#011loss=0.141023\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[100] avg_epoch_loss=0.155151\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=0.15359613597393035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [100]#011Speed: 2378.73 samples/sec#011loss=0.153596\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch[105] avg_epoch_loss=0.151816\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=0.08445464074611664\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[18] Batch [105]#011Speed: 11759.15 samples/sec#011loss=0.084455\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] processed a total of 6884 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214826.337658, \"EndTime\": 1711214828.5561666, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2218.083381652832, \"count\": 1, \"min\": 2218.083381652832, \"max\": 2218.083381652832}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3103.432907003815 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=18, train loss <loss>=0.15149153554294673\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch[0] avg_epoch_loss=0.357242\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=0.357242226600647\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch[5] avg_epoch_loss=0.249397\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=0.24939671903848648\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch [5]#011Speed: 11820.25 samples/sec#011loss=0.249397\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch[10] avg_epoch_loss=0.198182\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=0.13672374412417412\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch [10]#011Speed: 1843.20 samples/sec#011loss=0.136724\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch[15] avg_epoch_loss=0.172555\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=0.11617697328329087\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:08 INFO 140470849898304] Epoch[19] Batch [15]#011Speed: 9806.15 samples/sec#011loss=0.116177\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[20] avg_epoch_loss=0.168828\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=0.15689892172813416\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [20]#011Speed: 1756.09 samples/sec#011loss=0.156899\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[25] avg_epoch_loss=0.155505\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=0.09954920932650566\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [25]#011Speed: 11481.51 samples/sec#011loss=0.099549\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[30] avg_epoch_loss=0.145099\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=0.09099004492163658\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [30]#011Speed: 1785.15 samples/sec#011loss=0.090990\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[35] avg_epoch_loss=0.142633\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=0.1273433104157448\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [35]#011Speed: 10378.09 samples/sec#011loss=0.127343\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[40] avg_epoch_loss=0.139405\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=0.11616481691598893\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [40]#011Speed: 1845.94 samples/sec#011loss=0.116165\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[45] avg_epoch_loss=0.148605\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=0.22404226064682006\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [45]#011Speed: 10363.90 samples/sec#011loss=0.224042\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[50] avg_epoch_loss=0.146788\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=0.13007473424077035\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [50]#011Speed: 1830.63 samples/sec#011loss=0.130075\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[55] avg_epoch_loss=0.145624\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=0.13374890834093095\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [55]#011Speed: 10436.59 samples/sec#011loss=0.133749\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[60] avg_epoch_loss=0.145928\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=0.14933085031807422\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [60]#011Speed: 1901.21 samples/sec#011loss=0.149331\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch[65] avg_epoch_loss=0.153267\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=0.24280413389205932\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:09 INFO 140470849898304] Epoch[19] Batch [65]#011Speed: 10285.59 samples/sec#011loss=0.242804\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[70] avg_epoch_loss=0.157738\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=0.2167547583580017\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [70]#011Speed: 1834.65 samples/sec#011loss=0.216755\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[75] avg_epoch_loss=0.163674\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=0.2479703813791275\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [75]#011Speed: 10378.41 samples/sec#011loss=0.247970\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[80] avg_epoch_loss=0.161722\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=0.13205518424510956\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [80]#011Speed: 1856.87 samples/sec#011loss=0.132055\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[85] avg_epoch_loss=0.163249\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=0.18797603547573088\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [85]#011Speed: 11640.54 samples/sec#011loss=0.187976\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[90] avg_epoch_loss=0.163837\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=0.17395349889993666\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [90]#011Speed: 1882.73 samples/sec#011loss=0.173953\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[95] avg_epoch_loss=0.164461\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=0.17581744343042374\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [95]#011Speed: 11458.67 samples/sec#011loss=0.175817\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[100] avg_epoch_loss=0.162370\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=0.12223021239042282\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [100]#011Speed: 2511.21 samples/sec#011loss=0.122230\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch[105] avg_epoch_loss=0.158677\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=0.08407940603792667\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Epoch[19] Batch [105]#011Speed: 11398.82 samples/sec#011loss=0.084079\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] processed a total of 6825 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214828.5562258, \"EndTime\": 1711214830.737958, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 2181.43367767334, \"count\": 1, \"min\": 2181.43367767334, \"max\": 2181.43367767334}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #throughput_metric: host=algo-1, train throughput=3128.5454097763504 records/second\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, epoch=19, train loss <loss>=0.15719443416901838\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] loss did not improve\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Final loss: 0.14202202652868268 (occurred at epoch 13)\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] #quality_metric: host=algo-1, train final_loss <loss>=0.14202202652868268\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 WARNING 140470849898304] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214830.7380211, \"EndTime\": 1711214830.748751, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 10.123491287231445, \"count\": 1, \"min\": 10.123491287231445, \"max\": 10.123491287231445}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214830.7488015, \"EndTime\": 1711214830.7585964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 20.03645896911621, \"count\": 1, \"min\": 20.03645896911621, \"max\": 20.03645896911621}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214830.7586462, \"EndTime\": 1711214830.760179, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 1.5041828155517578, \"count\": 1, \"min\": 1.5041828155517578, \"max\": 1.5041828155517578}}}\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[03/23/2024 17:27:10 INFO 140470849898304] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1711214830.7602298, \"EndTime\": 1711214830.761139, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 4.630804061889648, \"count\": 1, \"min\": 4.630804061889648, \"max\": 4.630804061889648}, \"totaltime\": {\"sum\": 46667.39845275879, \"count\": 1, \"min\": 46667.39845275879, \"max\": 46667.39845275879}}}\u001b[0m\n",
      "\n",
      "2024-03-23 17:27:33 Uploading - Uploading generated training model\n",
      "2024-03-23 17:27:33 Completed - Training job completed\n",
      "Training seconds: 282\n",
      "Billable seconds: 282\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "deepar.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f97cda1e-1da0-41a9-b5ba-9a18500cf1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'nndss' \n",
    "key = 'deepar_input_data/deepar_dataset.jsonl'  \n",
    "\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "data = obj['Body'].read().decode('utf-8')\n",
    "deepar_training = data.strip().split('\\n')\n",
    "deepar_training = [json.loads(line) for line in deepar_training]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa96e59-0434-4bef-a336-8c136e667c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: forecasting-deepar-2024-03-23-17-27-57-227\n",
      "INFO:sagemaker:Creating endpoint-config with name forecasting-deepar-2024-03-23-17-27-57-227\n",
      "INFO:sagemaker:Creating endpoint with name forecasting-deepar-2024-03-23-17-27-57-227\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = deepar.deploy(\n",
    "    initial_instance_count=1,  # Number of instances to support the endpoint\n",
    "    instance_type='ml.m4.xlarge',  # Type of instance to run the endpoint\n",
    "    serializer=JSONSerializer(),  # Specify how to serialize the input data\n",
    "    deserializer=JSONDeserializer()  # Specify how to deserialize the prediction output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb19b9-fcef-4d0a-80d1-51a2d82c3e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing predictor input\n",
    "predictor_input = {\n",
    "    \"instances\": deepar_training,\n",
    "    \"configuration\": {\n",
    "        \"num_samples\": 100,\n",
    "        \"output_types\": [\"mean\", \"quantiles\"],\n",
    "        \"quantiles\": [\"0.01\", \"0.5\", \"0.99\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e2bd0-72cd-4e1f-973b-68d8c97e5cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = predictor.predict(predictor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9c9c7-4e74-4157-870e-8b979c985884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074f1b8-7a92-4125-9f03-984687b5ddd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def find_max_date(deepar_training):\n",
    "    latest_dates = []\n",
    "    for series in deepar_training:\n",
    "        start_date = datetime.strptime(series['start'], \"%Y-%m-%d\")\n",
    "        # Assuming weekly frequency, calculate the end date of each series\n",
    "        end_date = start_date + timedelta(weeks=len(series['target']) - 1)\n",
    "        latest_dates.append(end_date)\n",
    "    \n",
    "    # Find the maximum date across all series, which is the last known date in the dataset\n",
    "    max_date = max(latest_dates)\n",
    "    return max_date\n",
    "\n",
    "# Use the function to find the last known date in training data\n",
    "last_known_date = find_max_date(deepar_training)\n",
    "\n",
    "# The prediction_for_date is the next time period (e.g., the next week) after the last known date\n",
    "prediction_for_date = pd.to_datetime(last_known_date + timedelta(weeks=1))\n",
    "print(f\"The prediction is for the date: {prediction_for_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf333641-f8d8-4269-be0e-f4844f121770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list to store prediction data\n",
    "prediction_data = []\n",
    "\n",
    "# Iterate through each prediction and its corresponding item_id\n",
    "for idx, pred in enumerate(prediction['predictions']):\n",
    "    # Retrieve the item_id using the index\n",
    "    item_id = list(time_series_mapping.keys())[list(time_series_mapping.values()).index(idx)]\n",
    "    \n",
    "    # Extract quantiles\n",
    "    pred_lower = pred['quantiles']['0.01']\n",
    "    pred_upper = pred['quantiles']['0.99']\n",
    "    pred_median = pred['quantiles']['0.5']\n",
    "    pred_mean = pred['mean'] \n",
    "    \n",
    "    # Append the data to the list\n",
    "    prediction_data.append({\n",
    "        'item_id': item_id,\n",
    "        'pred_mean': pred_mean,\n",
    "        'pred_median':pred_median,\n",
    "        'pred_lower': pred_lower,\n",
    "        'pred_upper': pred_upper\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "prediction_df = pd.DataFrame(prediction_data)\n",
    "prediction_df['prediction_for_date'] = prediction_for_date\n",
    "prediction_df['pred_mean'] = prediction_df['pred_mean'].apply(lambda x: x[0] if x else None)\n",
    "prediction_df['pred_median'] = prediction_df['pred_median'].apply(lambda x: x[0] if x else None)\n",
    "prediction_df['pred_lower'] = prediction_df['pred_lower'].apply(lambda x: x[0] if x else None)\n",
    "prediction_df['pred_upper'] = prediction_df['pred_upper'].apply(lambda x: x[0] if x else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cdd49-843f-4938-8d70-d7fdeab35ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8ff43-187e-41c1-a924-48a389f92b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_df[prediction_df.pred_mean>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6fcf6-1c25-4b21-8b1c-d15b7efac09a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44d94b-5911-4e46-9b79-aa95d17a1232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc829be4-b332-4ce9-8310-f9d1774371e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify your S3 bucket and path\n",
    "bucket_name = 'nndss'\n",
    "folder_path = 'predictions'\n",
    "file_name = f\"weekly_predictions_{prediction_for_date.strftime('%Y-%m-%d')}.parquet\"\n",
    "s3_path = f's3://{bucket_name}/{folder_path}/{file_name}'\n",
    "\n",
    "# Save DataFrame to Parquet directly in S3\n",
    "prediction_df.to_parquet(s3_path, engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e50c33-ef95-4d70-8360-01b12ed37ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e84d3a7d-26de-4a60-955a-da6961f17d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here I would dump the latest weekly data (from weekly_staging) into weekly, and delete the file in weekly_staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb209a8-aed0-4572-8f21-048b9325f6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
